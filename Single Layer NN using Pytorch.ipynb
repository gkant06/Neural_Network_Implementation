{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d990aa5-fa69-4fb0-877a-829685eab62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional, List, Tuple, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca34794-0d99-4570-816c-85d1aeb4e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504d9785-458d-4d8d-aa87-bac678e94638",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS(Dataset):\n",
    "    def __init__(self, X: np.ndarray, Y: np.ndarray):\n",
    "        self.length = len(X)\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx, :]\n",
    "        y = self.Y[idx]\n",
    "        return (x, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e9fed8a-7da2-4b29-8ead-c0437a90bee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "indim = 10\n",
    "outdim = 2\n",
    "hidden_layer = 100\n",
    "lr = 0.01\n",
    "batch_size = 64\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c83544-8ff1-44d7-91df-4138541ddfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 10\n",
      "200 10\n"
     ]
    }
   ],
   "source": [
    "# Dataloader for training and test datasets\n",
    "\n",
    "Xtrain = np.loadtxt(\"/Users/kantg/OneDrive/Desktop/CMU/Neural Networks and Deep learning/data/XTrain.txt\", delimiter=\"\\t\")\n",
    "Ytrain = np.loadtxt(\"/Users/kantg/OneDrive/Desktop/CMU/Neural Networks and Deep learning/data/yTrain.txt\", delimiter=\"\\t\").astype(int)\n",
    "Ytrain = torch.from_numpy(Ytrain)\n",
    "Ytrain = Ytrain.type(torch.LongTensor)\n",
    "m1, n1 = Xtrain.shape\n",
    "print(m1, n1)\n",
    "train_ds = DS(Xtrain, Ytrain)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size)\n",
    "\n",
    "Xtest = np.loadtxt(\"/Users/kantg/OneDrive/Desktop/CMU/Neural Networks and Deep learning/data/XTest.txt\", delimiter=\"\\t\")\n",
    "Ytest = np.loadtxt(\"/Users/kantg/OneDrive/Desktop/CMU/Neural Networks and Deep learning/data/yTest.txt\", delimiter=\"\\t\").astype(int)\n",
    "Ytest = torch.from_numpy(Ytest)\n",
    "Ytest = Ytest.type(torch.LongTensor)\n",
    "m2, n2 = Xtest.shape\n",
    "print(m2, n2)\n",
    "test_ds = DS(Xtest, Ytest)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f506921b-9a9e-4d6e-a35c-604b79b33a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerMLP(nn.Module):\n",
    "    \"\"\"constructing a single layer neural network with Pytorch\"\"\"\n",
    "    def __init__(self, indim, outdim, hidden_layer):\n",
    "        super(SingleLayerMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(indim, hidden_layer)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_layer, outdim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89a2ee50-227d-4269-8793-5020a1cac16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingleLayerMLP(\n",
      "  (fc1): Linear(in_features=10, out_features=100, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network\n",
    "\n",
    "model = SingleLayerMLP(indim, outdim, hidden_layer).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12e81742-0b33-4b13-93fd-3388cfe0266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b25d13ee-ea4c-4637-987e-a6865ab51842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "def train(train_loader, model, loss_function, optimizer):\n",
    "    size = len(train_loader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_function(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_size % 100 == 0:\n",
    "            loss, current = loss.item(), (batch_size + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "# Validation using the test dataset \n",
    "\n",
    "def validate(test_loader, model, loss_function):\n",
    "    size = len(test_loader.dataset)\n",
    "    num_batches = len(test_loader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_function(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d5caf1f-221a-4e00-88de-a5519a7e85a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.249075 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.172940 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.154210 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.150129 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.149370 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.148486 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.145583 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.145257 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.145052 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.144081 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.142612 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.5%, Avg loss: 0.142898 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.142710 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.143086 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.145708 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.148642 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.150030 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.151921 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.153492 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.158191 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.160366 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.163860 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.167534 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.168831 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.172300 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.176366 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.178967 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.180625 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.182866 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.186783 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.189321 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.190457 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.193440 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.196977 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.198413 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.202336 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.205631 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.206529 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.209896 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.212861 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.214005 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.217025 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.219501 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.221197 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.223238 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.225732 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.229410 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.231457 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.232966 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.235852 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.238071 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.239748 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.242569 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.245684 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.248263 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.250567 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.251540 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.253969 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.256981 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.258607 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.260374 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.261903 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.263327 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.265674 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.267873 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.269404 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.271255 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.272511 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.274177 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.276352 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.277444 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.278351 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.280657 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.282748 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.284235 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.285632 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.286405 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.287984 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.289550 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.290873 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.292375 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.293715 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.295031 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.295875 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.297372 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.299436 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.300484 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.301176 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.302522 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.303836 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.304614 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.305935 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.307303 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.308657 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.309770 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.310796 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.311597 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.312810 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.313910 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.314743 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.315923 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.316859 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.317732 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.319174 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.320384 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.320921 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.322032 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.322666 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.323509 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.324740 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.325929 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.326731 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.327812 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.328756 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.329289 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.330332 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.331207 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.331678 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.332680 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.333636 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.334267 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.335098 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.335865 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.336572 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.337554 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.338314 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.338947 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.339798 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.340400 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.340776 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.341723 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.342720 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.343306 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.343945 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.344762 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.345421 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.345981 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.346450 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.347163 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.347847 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.348544 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.348875 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.349592 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.350392 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.350923 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.351607 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.352305 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.352844 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.353611 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.354016 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.354546 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.355179 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.355744 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.356241 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.357046 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.357593 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.358222 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.358707 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.359280 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.359796 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.360484 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.361053 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.361608 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.362085 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.362585 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.363106 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.363545 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.363972 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.364684 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.365137 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.365592 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.366407 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.366966 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.367193 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.367885 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.368630 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.369078 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.369513 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.369939 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.370571 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.371053 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.371565 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.372342 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.373173 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.373483 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.373844 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.374527 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.375240 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.375836 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.376200 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.376709 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.377374 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.377997 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.378489 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.379095 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.379612 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.380148 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.380698 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.381074 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.381682 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_function, optimizer)\n",
    "    validate(test_loader, model, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3037ae8b-cee2-4b1c-bddb-28adde9f5213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e342867-4b73-4ee4-9010-051d5036e622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
